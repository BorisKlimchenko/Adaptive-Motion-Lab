{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6711d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Initialize & Hardware Check\n",
    "import os\n",
    "import torch\n",
    "from google.colab import drive\n",
    "\n",
    "# 1. Mount Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Clone/Update Repo\n",
    "REPO_URL = \"https://github.com/BorisKlimchenko/Adaptive-Motion-Lab.git\"\n",
    "REPO_DIR = \"/content/Adaptive-Motion-Lab\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print(f\"Cloning {REPO_URL}...\")\n",
    "    !git clone {REPO_URL}\n",
    "else:\n",
    "    print(\"Pulling latest changes...\")\n",
    "    !cd {REPO_DIR} && git pull\n",
    "\n",
    "# 3. Hardware Check\n",
    "print(\"\\n--- Hardware Profile ---\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu = torch.cuda.get_device_name(0)\n",
    "    print(f\"GPU: {gpu}\")\n",
    "    if \"T4\" in gpu: print(\"‚ÑπÔ∏è Mode: Efficiency (T4)\")\n",
    "    elif \"A100\" in gpu: print(\"üöÄ Mode: Performance (A100)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected!\")\n",
    "\n",
    "%cd {REPO_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c8cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ‚ö° –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è (The Golden Trio)\n",
    "# @markdown –≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç —É–¥–∞–ª—è–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—â–∏–µ –≤–µ—Ä—Å–∏–∏ –∏ —Å—Ç–∞–≤–∏—Ç —Å—Ç—Ä–æ–≥–æ:\n",
    "# @markdown - PyTorch 2.5.1 (CUDA 12.1)\n",
    "# @markdown - xFormers 0.0.28\n",
    "# @markdown - Diffusers & Transformers\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def run_command(command, msg):\n",
    "    print(f\"üîÑ {msg}...\")\n",
    "    try:\n",
    "        subprocess.check_call(command, shell=True)\n",
    "        print(f\"‚úÖ –£—Å–ø–µ—à–Ω–æ.\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏: {msg}\")\n",
    "        sys.exit(1) # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ –±–∞–∑–∞ –Ω–µ –≤—Å—Ç–∞–ª–∞\n",
    "\n",
    "# 1. –ó–ê–ß–ò–°–¢–ö–ê (Nuke & Pave)\n",
    "# –£–¥–∞–ª—è–µ–º –≤—Å—ë, —á—Ç–æ –º–æ–∂–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞—Ç—å. –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è Colab.\n",
    "run_command(\n",
    "    \"pip uninstall -y torch torchvision torchaudio xformers\",\n",
    "    \"–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è PyTorch\"\n",
    ")\n",
    "\n",
    "# 2. –§–£–ù–î–ê–ú–ï–ù–¢ (Golden Trio)\n",
    "# –°—Ç–∞–≤–∏–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤–µ—Ä—Å–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ —Ä–∞–±–æ—Ç–∞—é—Ç –≤–º–µ—Å—Ç–µ.\n",
    "# --no-deps –¥–ª—è xformers –≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã –æ–Ω –Ω–µ —Ç—è–Ω—É–ª —Å–≤–æ–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.\n",
    "run_command(\n",
    "    \"pip install torch==2.5.1+cu121 torchvision==0.20.1+cu121 torchaudio==2.5.1+cu121 xformers==0.0.28.post3 --index-url https://download.pytorch.org/whl/cu121\",\n",
    "    \"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —è–¥—Ä–∞: Torch 2.5.1 + xFormers 0.0.28\"\n",
    ")\n",
    "\n",
    "# 3. –ü–†–ò–õ–û–ñ–ï–ù–ò–ï\n",
    "# –¢–µ–ø–µ—Ä—å –Ω–∞–∫–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏–∑ requirements.txt\n",
    "run_command(\n",
    "    \"pip install -r requirements.txt\",\n",
    "    \"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ –ø—Ä–æ–µ–∫—Ç–∞ (Diffusers, etc.)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82feced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Run Inference Engine\n",
    "# –ó–¥–µ—Å—å –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –ø—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É, –∫–æ—Ç–æ—Ä—ã–π –º—ã —Ç–æ–ª—å–∫–æ —á—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–ª–∏!\n",
    "CONFIG_PATH = \"configs/default_scene.json\" \n",
    "\n",
    "print(f\"üöÄ Launching Engine with: {CONFIG_PATH}\")\n",
    "!python main.py --prompts {CONFIG_PATH}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
